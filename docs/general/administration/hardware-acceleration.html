<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Hardware Acceleration | Documentation - Jellyfin Project </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Hardware Acceleration | Documentation - Jellyfin Project ">
    <meta name="generator" content="docfx 2.59.3.0">
    
    <link rel="shortcut icon" href="../../images/favicon.png">
    <link rel="stylesheet" href="../../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../../styles/docfx.css">
    <link rel="stylesheet" href="../../styles/main.css">
    <meta property="docfx:navrel" content="../../toc.html">
    <meta property="docfx:tocrel" content="../toc.html">
    
    <meta property="docfx:rel" content="../../">
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../../index.html">
                <img id="logo" class="svg" src="../../images/header-icon.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">
        
        <div id="search-results">
          <div class="search-list">Search Results for <span></span></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination" data-first="First" data-prev="Previous" data-next="Next" data-last="Last"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="admin-hardware-acceleration">
<h1 id="hardware-acceleration">Hardware Acceleration</h1>

<p>Jellyfin supports <a href="https://trac.ffmpeg.org/wiki/HWAccelIntro">hardware acceleration (HWA) of video encoding/decoding using FFMpeg</a>.
FFMpeg and Jellyfin can support multiple hardware acceleration implementations such as Intel Quicksync (QSV), AMD AMF and NVIDIA NVENC/NVDEC through Video Acceleration APIs.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Video_Acceleration_API">VA-API</a> is a Video Acceleration API that uses <a href="https://github.com/intel/libva/blob/master/README.md">libva</a> to interface with local drivers to provide HWA.</li>
<li><a href="https://trac.ffmpeg.org/wiki/Hardware/QuickSync">QSV</a> uses a modified (forked) version of VA-API and interfaces it with <a href="https://github.com/intel/media-driver/blob/master/README.md">libmfx</a> and their proprietary drivers <a href="https://ark.intel.com/content/www/us/en/ark.html#@Processors">(list of supported processors for QSV)</a>.</li>
</ul>
<table>
<thead>
<tr>
<th>OS</th>
<th>Recommended HW Acceleration</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux</td>
<td>QSV, NVENC, AMF, VA-API</td>
</tr>
<tr>
<td>Windows</td>
<td>QSV, NVENC, AMF</td>
</tr>
<tr>
<td>MacOS</td>
<td>VideoToolbox</td>
</tr>
<tr>
<td>RPi</td>
<td>V4L2</td>
</tr>
</tbody>
</table>
<p><a href="https://www.elpamsoft.com/?p=Plex-Hardware-Transcoding">Graphics Cards comparison using HWA</a></p>
<p>Based on hardware vendor:</p>
<table>
<thead>
<tr>
<th>Vendor</th>
<th>Supported HW Acceleration</th>
</tr>
</thead>
<tbody>
<tr>
<td>NVIDIA</td>
<td>NVENC</td>
</tr>
<tr>
<td>AMD</td>
<td>AMF, VA-API</td>
</tr>
<tr>
<td>Intel</td>
<td>QSV, VA-API</td>
</tr>
<tr>
<td>Apple</td>
<td>VideoToolbox</td>
</tr>
<tr>
<td>RPi</td>
<td>V4L2</td>
</tr>
</tbody>
</table>
<h2 id="enabling-hardware-acceleration">Enabling Hardware Acceleration</h2>
<p>Hardware acceleration options can be found in the Admin Dashboard under the <strong>Transcoding</strong> section of the <strong>Playback</strong> tab.
Select a valid hardware acceleration option from the drop-down menu, indicate a device if applicable, and check <code>Enable hardware encoding</code> to enable encoding as well as decoding, if your hardware supports this.</p>
<p>The hardware acceleration is available immediately for media playback. No server restart is required.</p>
<p>On Linux you can check available GPU using:</p>
<pre><code class="lang-sh">lspci -nn | egrep -i &quot;3d|display|vga&quot;
</code></pre><p>or using <code>lshw</code>:</p>
<pre><code class="lang-sh">lshw -C display
</code></pre><h2 id="h264--avc-10-bit-videos">H.264 / AVC 10-bit videos</h2>
<p>The hardware decoding of H.264 10-bit aka High10 profile video is not supported by any Intel, AMD or NVIDIA GPU.</p>
<p>Please consider upgrading these videos to HEVC 10-bit aka Main10 profile if you want to offload your CPU usage during transcoding.</p>
<h2 id="intel-gen9-and-gen11-igpus">Intel Gen9 and Gen11+ iGPUs</h2>
<div class="NOTE"><h5>Note</h5><p>The Intel <a href="https://01.org/linuxgraphics/downloads/firmware">Guc/Huc firmware</a> must be enabled for optional Low-Power encoding (pre-Gen11 only supports Low-Power H.264).</p>
</div>
<p>Instructions:</p>
<ul>
<li>ArchLinux: <a href="https://wiki.archlinux.org/title/intel_graphics#Enable_GuC_/_HuC_firmware_loading">Arch Wiki</a></li>
<li>Debian/Ubuntu: <a href="https://gist.github.com/Brainiarc7/aa43570f512906e882ad6cdd835efe57">Brainiarc7&#39;s gist</a></li>
</ul>
<div class="WARNING"><h5>Warning</h5><p>For <strong>Jasper Lake</strong> and <strong>Elkhart Lake</strong> chips (such as <code>N5095</code>, <code>N6005</code> and <code>J6412</code>), Low-Power encoding <strong>must</strong> be enabled.
There&#39;s a known kernel issue on these chips in <strong>linux 5.15</strong> that comes with Ubuntu 22.04 LTS preventing you from using Low-Power. You may need to upgrade kernel for this.
The linux-firmware support is <strong>not included</strong> in Ubuntu 20.04.3 LTS.
Any Ubuntu from 21.10 <strong>does include</strong> the required drivers.</p>
</div>
<h2 id="supported-acceleration-methods">Supported Acceleration Methods</h2>
<div class="IMPORTANT"><h5>Important</h5><p>In Jellyfin 10.8 full hardware-accelerated filtering (scaling, deinterlacing, tone-mapping and subtitle burn-in) on Intel, AMD and NVIDIA hardware are available.</p>
<p><strong>jellyfin-ffmpeg version 4.4.1-2 or higher is required</strong>, using an older or original version of FFmpeg may disable some hardware filtering improvements.</p>
</div>
<h3 id="va-api">VA-API</h3>
<div class="NOTE"><h5>Note</h5><p>Intel iGPU and AMD GPU only.</p>
</div>
<p>A List of supported codecs for VA-API can be found <a href="https://wiki.archlinux.org/index.php/Hardware_video_acceleration#Comparison_tables">on the Archlinux wiki</a>.</p>
<div class="WARNING"><h5>Warning</h5><p>As of <strong>Jellyfin 10.8</strong> the official Docker image uses Debian 11 which has a compatible version of Mesa for <strong>AMD GPU HEVC</strong> decoding.</p>
<p>Earlier images do not provide a compatible version of Mesa.</p>
</div>
<h3 id="hardware-acceleration-on-raspberry-pi-3-and-4">Hardware acceleration on Raspberry Pi 3 and 4</h3>
<div class="WARNING"><h5>Warning</h5><p>As of <strong>Jellyfin 10.8</strong> hardware acceleration on Raspberry Pi via <code>OpenMAX OMX</code> was dropped and is no longer available.</p>
<p>This decision was made because Raspberry Pi is currently migrating to a <code>V4L2</code> based hardware acceleration, which is already available in Jellyfin but does not support all features other hardware acceleration methods provide due to lacking support in FFmpeg.
Jellyfin will fallback to software de- and encoding for those usecases.</p>
<p>The current state of hardware acceleration support in FFmpeg can be checked on the <a href="https://github.com/jc-kynesim/rpi-ffmpeg">rpi-ffmpeg repository</a>.</p>
</div>
<h3 id="nvidia-nvenc">NVIDIA NVENC</h3>
<div class="NOTE"><h5>Note</h5><p><strong>Minimum required driver version since Jellyfin 10.8:</strong></p>
<ul>
<li><strong>Linux:</strong> 470.57.02</li>
<li><strong>Windows:</strong> 471.41</li>
</ul>
</div>
<p>Not every card has been tested.</p>
<p>If you want more than three parallel transcoding streams on a consumer (non-Quadro) NVIDIA card, you can use <a href="https://github.com/keylase/nvidia-patch">this patch</a> to remove the limit.
The patch is recommended for Linux and Windows but may break in the future, so check the compatible driver versions before applying it.</p>
<p>On Linux use <code>nvidia-smi</code> to check driver and GPU card version.</p>
<p><strong>Useful links:</strong></p>
<ul>
<li><a href="https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new">Official list of supported codecs for recent NVIDIA Graphics Cards</a>.</li>
<li><a href="https://developer.nvidia.com/ffmpeg">Official NVIDIA ffmpeg development docs</a>.</li>
</ul>
<h3 id="amd-amf">AMD AMF</h3>
<div class="NOTE"><h5>Note</h5><p>AMF is available on Windows and Linux.</p>
</div>
<div class="WARNING"><h5>Warning</h5><p>As of <strong>Jellyfin 10.8</strong> full OpenCL based hardware filtering in AMF is supported on Windows 10 and newer.</p>
<p>AMD has not implemented the Vulkan based HW decoder and scaler in ffmpeg, the decoding speed may not be as expected on Linux.</p>
<p>The closed source driver <code>amdgpu-pro</code> is required when using AMF on Linux.</p>
</div>
<div class="TIP"><h5>Tip</h5><p>Most Zen CPUs <strong>do not</strong> come with integrated graphics. You will need a <strong>dedicated GPU</strong> (dGPU) or a Zen CPU with integrated graphics for hardware acceleration.
If your Zen CPU is suffixed with a <em>G</em> or <em>GE</em> in model name, you have integrated graphics.</p>
</div>
<h3 id="intel-quicksync">Intel QuickSync</h3>
<div class="NOTE"><h5>Note</h5><p>Intel QuickSync (QSV) is derived from VA-API on Linux and D3D11VA on Windows, which can utilize Intel&#39;s fixed function hardware and EU(execution units) to do video encoding, decoding and processing.</p>
</div>
<div class="IMPORTANT"><h5>Important</h5><p>To use QSV on Linux with recent Intel iGPUs the <strong>nonfree <a href="https://github.com/intel/media-driver">Intel media driver</a></strong> is required for full hardware acceleration.
If you are using <code>jellyfin-ffmpeg</code> version 4.4.1-2 or higher it is included and you do not need to install it seperatly.
Broadwell or newer generation is required for QSV on Linux, otherwise you have to use VA-API.</p>
</div>
<p><strong>Useful links:</strong></p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/develop/documentation/media-capabilities-of-intel-hardware/top.html">Official list of supported codecs for recent Intel Graphics Cards</a>.</li>
<li><a href="https://www.intel.com/content/www/us/en/architecture-and-technology/quick-sync-video/quick-sync-video-installation.html">Intel QSV Benchmarks on Linux</a></li>
<li><a href="https://github.com/Artiume/jellyfin-docs/blob/master/general/wiki/main.md">Collection of useful links and information</a></li>
</ul>
<hr>
<div class="TIP"><h5>Tip</h5><p>If your Jellyfin server does not support hardware acceleration, but you have another machine that does, you can leverage <a href="https://github.com/joshuaboniface/rffmpeg">rffmpeg</a> to delegate the transcoding to another machine.
Currently Linux-only and requires SSH between the machines, as well as shared storage both for media and for the Jellyfin data directory.</p>
</div>
<h2 id="common-setups">Common setups</h2>
<p>Each hardware acceleration type, as well as each Jellyfin installation type, has different prerequisites for enabling hardware acceleration.
It is always best to consult <a href="https://trac.ffmpeg.org/wiki/HWAccelIntro">the FFMpeg documentation</a> on the acceleration type you choose for the latest information.</p>
<h3 id="hardware-acceleration-on-docker-linux">Hardware acceleration on Docker (Linux)</h3>
<div class="NOTE"><h5>Note</h5><p>This are general instructions, for more specific instructions pleas check the next sections!</p>
</div>
<p>In order to use hardware acceleration in Docker, the devices must be passed to the container.
To see what video devices are available, you can run <code>sudo lshw -c video</code> or <code>vainfo</code> on your machine.
VA-API may require the <code>render</code> group added to the docker permissions.
The <code>render</code> group id can be discovered in <code>/etc/group</code> such as <code>render:x:122:</code>.</p>
<p>You can use <code>docker run</code> to start the server with the required permissions and devices.
An example command is shown below.</p>
<pre><code class="lang-sh">docker run -d \
 --volume /path/to/config:/config \
 --volume /path/to/cache:/cache \
 --volume /path/to/media:/media \
 --user 1000:1000 \
 --group-add=122 \ # Change this to match your system
 --net=host \
 --restart=unless-stopped \
 --device /dev/dri/renderD128:/dev/dri/renderD128 \
 --device /dev/dri/card0:/dev/dri/card0 \
 jellyfin/jellyfin
</code></pre><p>Alternatively, you can use docker-compose with a configuration file so you don&#39;t need to run a long command every time you restart your server.</p>
<pre><code class="lang-yaml">version: &quot;3&quot;
services:
  jellyfin:
    image: jellyfin/jellyfin
    user: 1000:1000
    group_add:
      - 122
    network_mode: &quot;host&quot;
    volumes:
      - /path/to/config:/config
      - /path/to/cache:/cache
      - /path/to/media:/media
    devices:
      # VAAPI Devices (examples)
      - /dev/dri/renderD128:/dev/dri/renderD128
      - /dev/dri/card0:/dev/dri/card0
</code></pre><h3 id="nvidia-hardware-acceleration-on-docker-linux">NVIDIA hardware acceleration on Docker (Linux)</h3>
<p>In order to achieve hardware acceleration using Docker, several steps are required.</p>
<p>Prerequisites:</p>
<ul>
<li>GNU/Linux x86_64 with kernel version &gt; 3.10</li>
<li>Docker &gt;= 19.03</li>
<li>NVIDIA GPU with Architecture &gt; Fermi (2.1)</li>
<li>NVIDIA drivers &gt;= 361.93</li>
<li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#getting-started">NVIDIA Container Toolkit</a> needs to be installed</li>
</ul>
<p>Follow the instructions in the link above to install the NVIDIA Container Toolkit for your Linux distribution.</p>
<p>Start your container by adding this parameter:</p>
<pre><code class="lang-sh">--gpus all \
</code></pre><p>A complete run command would look like this:</p>
<pre><code class="lang-sh">docker run -d \
 --name=jellyfin \
 --gpus all \
 -p 8096:8096 \
 -p 8920:8920 \
 -v /config:/config \
 -v /media:/media \
 -v /cache:/cache \
 --restart unless-stopped \
 jellyfin/jellyfin
</code></pre><p>Or with docker-compose &gt;1.28, add the <code>deploy</code> section to your Jellyfin service:</p>
<pre><code class="lang-yaml">services:
  jellyfin:
    image: jellyfin/jellyfin
    # ... your Jellyfin config
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
</code></pre><p>There are some special steps when running with the following option:</p>
<pre><code class="lang-sh">--user 1000:1000
</code></pre><p>You may need to add this user to the video group on your host machine:</p>
<pre><code class="lang-sh">usermod -aG video &lt;user&gt;
</code></pre><p>Once the container is started you can again validate access to the host resources:</p>
<pre><code class="lang-sh">docker exec -it jellyfin nvidia-smi
</code></pre><p>If you get driver information, everything is fine but if you get an error like <code>couldn&#39;t find libnvidia-ml.so library in your system</code> you need to run the following command:</p>
<pre><code class="lang-sh">docker exec -it jellyfin ldconfig
</code></pre><p>After that, you should ensure the NVIDIA driver loads correctly.</p>
<div class="NOTE"><h5>Note</h5><p>The official Jellyfin Docker image already sets the required environment variables to allow access to the GPUs via the NVIDIA container runtime.
If you are building your own image don&#39;t forget to include <code>NVIDIA_DRIVER_CAPABILITIES=all</code> and  <code>NVIDIA_VISIBLE_DEVICES=all</code> into your container&#39;s environment.</p>
</div>
<h3 id="va-api-hardware-acceleration-on-debianubuntu">VA-API hardware acceleration on Debian/Ubuntu</h3>
<p>Configuring VA-API on Debian/Ubuntu requires some additional configuration to ensure permissions are correct.</p>
<ol>
<li><p>Configure VA-API for your system by following the documentation of your OS and/or vendor.
Verify that a <code>render</code> device is now present in <code>/dev/dri</code>, and note the permissions and group available to write to it, in this case <code>render</code>:</p>
<pre><code class="lang-sh">$ ls -l /dev/dri
total 0
drwxr-xr-x 2 root root        100 Apr 13 16:37 by-path
crw-rw---- 1 root video  226,   0 Apr 13 16:37 card0
crw-rw---- 1 root video  226,   1 Apr 13 16:37 card1
crw-rw---- 1 root render 226, 128 Apr 13 16:37 renderD128
</code></pre><div class="NOTE"><h5>Note</h5><p>On some releases, the group may be <code>video</code> or <code>input</code> instead of <code>render</code>.</p>
</div>
</li>
<li><p>Make sure that <code>jellyfin-ffmpeg</code> version 4.4.1-2 or higher is installed.</p>
</li>
<li><p>Check the output of <code>/usr/lib/jellyfin-ffmpeg/vainfo</code>.</p>
</li>
<li><p>Add the Jellyfin service user to the above group to allow Jellyfin&#39;s FFMpeg process access to the device, and restart Jellyfin.</p>
<pre><code class="lang-sh">sudo usermod -aG render jellyfin
sudo systemctl restart jellyfin
</code></pre></li>
<li><p>Configure VA-API acceleration in the <code>Transcoding</code> page of the Admin Dashboard.
Enter the <code>/dev/dri/renderD128</code> device above as the <code>VA API Device</code> value.</p>
</li>
<li><p>Watch a movie, and verify that transcoding is occurring by watching the <code>ffmpeg-transcode-*.txt</code> logs under <code>/var/log/jellyfin</code> and using <code>radeontop</code> (AMD only) or similar tools.</p>
</li>
</ol>
<h3 id="intel-quicksync-qsv-hardware-acceleration-on-debianubuntu">Intel QuickSync (QSV) hardware acceleration on Debian/Ubuntu</h3>
<ol>
<li><p>QSV is based on VA-API device on Linux, so please confirm whether you have completed the VA-API configuration first.</p>
</li>
<li><p>Make sure that <code>jellyfin-ffmpeg</code> version 4.4.1-2 or higher is installed (it ships the current version of <code>intel-media-driver (iHD)</code> which is required for QSV).</p>
</li>
<li><p>Verify that the iHD driver is properly loaded and recognizes your iGPU.</p>
<pre><code class="lang-sh">sudo /usr/lib/jellyfin-ffmpeg/vainfo | grep iHD
</code></pre></li>
<li><p>Configure QSV acceleration in the <code>Transcoding</code> page of the Admin Dashboard.</p>
</li>
<li><p>Watch a movie, and verify that transcoding is occurring by watching the <code>ffmpeg-transcode-*.txt</code> logs under <code>/var/log/jellyfin</code> and using <code>intel_gpu_top</code> (can be installed with the <code>intel-gpu-tools</code> package).</p>
</li>
</ol>
<h3 id="va-api-and-qsv-hardware-acceleration-on-lxc-or-lxd-container">VA-API and QSV hardware acceleration on LXC or LXD container</h3>
<div class="WARNING"><h5>Warning</h5><p>This has been tested with LXC 3.0 and may or may not work with older versions.</p>
</div>
<p>Follow the steps above to add the jellyfin user to the <code>video</code> or <code>render</code> group, depending on your circumstances.</p>
<ol>
<li><p>Install the required drivers on the host OS</p>
</li>
<li><p>Add your GPU to the container.</p>
<pre><code class="lang-sh">lxc config device add &lt;container name&gt; gpu gpu gid=&lt;gid of your video or render group&gt;
</code></pre></li>
<li><p>Make sure you have the required devices within the container:</p>
<pre><code class="lang-sh">$ lxc exec jellyfin -- ls -l /dev/dri
total 0
crw-rw---- 1 root video 226,   0 Jun  4 02:13 card0
crw-rw---- 1 root video 226,   0 Jun  4 02:13 controlD64
crw-rw---- 1 root video 226, 128 Jun  4 02:13 renderD128
</code></pre></li>
<li><p>Configure Jellyfin to use video acceleration and point it at the right device if the default option is wrong.</p>
</li>
<li><p>Try and play a video that requires transcoding and run the following, you should get a hit.</p>
<pre><code class="lang-sh">ps aux | grep ffmpeg | grep accel
</code></pre></li>
<li><p>You can also try playing a video that requires transcoding, and if it plays you&#39;re good.</p>
</li>
</ol>
<p>Useful resources:</p>
<ul>
<li><a href="https://github.com/lxc/lxd/blob/master/doc/instances.md#type-gpu">LXD Documentation - GPU instance configuration</a></li>
<li><a href="https://stgraber.org/2017/03/21/cuda-in-lxd/">NVIDIA CUDA inside a LXD container</a></li>
</ul>
<h3 id="va-api-and-qsv-hardware-acceleration-on-lxc-on-proxmox">VA-API and QSV hardware acceleration on LXC on Proxmox</h3>
<div class="IMPORTANT"><h5>Important</h5><p>Jellyfin needs to run in a <strong>privileged</strong> LXC container.
You can convert an existing unprivileged container to a privileged container by taking a backup and restoring it as priviledged.</p>
</div>
<ol>
<li><p>Install the required drivers on the Proxmox host</p>
</li>
<li><p>Add your GPU to the container by editing <code>/etc/pve/lxc/&lt;container-id&gt;.conf</code> (you may need to change the GIDs in the examples below to match those used on you host).</p>
<div class="WARNING"><h5>Warning</h5><p>This has been tested on <code>Proxmox VE 7.1</code> - on previous versions you may need to change <code>cgroup2</code> to <code>cgroup</code>.</p>
</div>
<p>Intel iGPU:</p>
<pre><code class="lang-conf">lxc.cgroup2.devices.allow: c 226:0 rwm
lxc.cgroup2.devices.allow: c 226:128 rwm
lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file
lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file
</code></pre><p>NVidia GPU:</p>
<pre><code class="lang-conf">lxc.cgroup2.devices.allow: c 195:* rwm
lxc.cgroup2.devices.allow: c 243:* rwm
lxc.mount.entry: /dev/nvidia0 dev/nvidia0 none bind,optional,create=file
lxc.mount.entry: /dev/nvidiactl dev/nvidiactl none bind,optional,create=file
lxc.mount.entry: /dev/nvidia-uvm dev/nvidia-uvm none bind,optional,create=file
lxc.mount.entry: /dev/nvidia-modeset dev/nvidia-modeset none bind,optional,create=file
lxc.mount.entry: /dev/nvidia-uvm-tools dev/nvidia-uvm-tools none bind,optional,create=file
</code></pre></li>
<li><p>Shutdown and start your container.</p>
</li>
<li><p>Install the required drivers in your container.</p>
</li>
<li><p>Add the jellyfin user to the <code>video</code>, <code>render</code> and/or <code>input</code> groups depending on who owns the device inside the container.</p>
</li>
<li><p>Configure Jellyfin to use hardware acceleration and point it at the right device if the default option is wrong.</p>
</li>
<li><p>Try and play a video that requires transcoding and run the following, you should get a hit.</p>
<pre><code class="lang-sh">ps aux | grep ffmpeg | grep accel
</code></pre></li>
<li><p>You can also try playing a video that requires transcoding, and if it plays you&#39;re good.</p>
</li>
</ol>
<h3 id="amd-amf-encoding-on-ubuntu-1804-or-2004-lts">AMD AMF encoding on Ubuntu 18.04 or 20.04 LTS</h3>
<ol>
<li><p>Install the <code>amdgpu-pro</code> closed source graphics driver by following the <a href="https://amdgpu-install.readthedocs.io/en/latest/">installation instructions</a>.</p>
</li>
<li><p>Then install <code>amf-amdgpu-pro</code>.</p>
<pre><code class="lang-bash">sudo apt install amf-amdgpu-pro
</code></pre></li>
<li><p>Check if <code>jellyfin-ffmpeg</code> contains <code>h264_amf</code> encoder:</p>
<pre><code class="lang-bash">$ cd /usr/lib/jellyfin-ffmpeg/
$ ./ffmpeg -encoders | grep h264_amf
V..... h264_amf             AMD AMF H.264 Encoder (codec h264)
</code></pre><div class="NOTE"><h5>Note</h5><p>If not available, update your <code>jellyfin-ffmpeg</code> to the latest version and try again.</p>
</div>
</li>
<li><p>Choose AMD AMF video acceleration in Jellyfin and check the <code>Enable hardware encoding</code> option.</p>
</li>
<li><p>Watch a movie, then verify that <code>h264_amf</code> encoder is working by watching the <code>ffmpeg-transcode-*.txt</code> transcoding logs under <code>/var/log/jellyfin</code> and using <code>radeontop</code> or similar tools.</p>
</li>
</ol>
<h3 id="amd-amf-encoding-on-arch-linux">AMD AMF encoding on Arch Linux</h3>
<p>AMD does not provide official <code>amdgpu-pro</code> driver support for Arch Linux, but fortunately, a third-party packaged <code>amdgpu-pro-installer</code> is provided in the archlinux user repository.</p>
<ol>
<li><p>Clone <a href="https://aur.archlinux.org/pkgbase/amdgpu-pro-installer/">this repository</a> using <code>git</code>.</p>
<pre><code class="lang-bash">git clone https://aur.archlinux.org/amdgpu-pro-installer.git
</code></pre></li>
<li><p>Enter that folder and make the installation package and install it.</p>
<pre><code class="lang-bash">cd amdgpu-pro-installer
makepkg -si
</code></pre></li>
<li><p>Go to step 3 of <a href="#amd-amf-encoding-on-ubuntu-1804-or-2004-lts">Configuring AMD AMF encoding on Ubuntu 18.04 or 20.04 LTS</a> above.</p>
</li>
</ol>
<h3 id="opencl--cuda--intel-vpp-tone-mapping">OpenCL / CUDA / Intel VPP Tone-Mapping</h3>
<p>Hardware based HDR10/HLG/DoVi tone-mapping with NVIDIA NVENC, AMD AMF, Intel QSV and VA-API is done through OpenCL or CUDA. DoVi Profile 5 and 8 tone-mapping requires <code>jellyfin-ffmpeg</code> version 5.0.1-5 or higher.</p>
<p>Intel hardware based VPP HDR10 tone-mapping is supported on Intel QSV and VA-API on Linux.
VPP is prefered when both two tone-mapping options are checked on Intel.</p>
<table>
<thead>
<tr>
<th>OS/Platform</th>
<th>NVIDIA NVENC</th>
<th>AMD AMF</th>
<th>Intel QSV</th>
<th>Intel VA-API</th>
<th>AMD VA-API</th>
<th>Software</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>WIP</td>
</tr>
<tr>
<td>Windows</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>N/A</td>
<td>N/A</td>
<td>WIP</td>
</tr>
<tr>
<td>Docker</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>✔️</td>
<td>WIP</td>
</tr>
</tbody>
</table>
<div class="NOTE"><h5>Note</h5><p>Tone-mapping on Windows with Intel QSV and AMD AMF requires Windows 10 or newer.</p>
</div>
<div class="IMPORTANT"><h5>Important</h5><p>Make sure the hardware acceleration is well configured before configuring tone-mapping with this instructions.</p>
</div>
<ol>
<li><p><strong>On Windows:</strong> Install the latest NVIDIA, AMD or Intel drivers.</p>
</li>
<li><p><strong>On Linux or Docker:</strong></p>
<ul>
<li>For <strong>NVIDIA cards</strong> no further configuration is necessary.</li>
<li><p>For <strong>AMD cards</strong>, install <code>amdgpu-pro</code> with opencl arguments (see <a href="#amd-amf-encoding-on-ubuntu-1804-or-2004-lts">Configuring AMD AMF encoding on Ubuntu 18.04 or 20.04 LTS</a> for more details):</p>
<pre><code class="lang-sh">sudo ./amdgpu-pro-install -y --opencl=pal,legacy
sudo usermod -aG video $LOGNAME
sudo usermod -aG render $LOGNAME
</code></pre></li>
<li><p>For <strong>Intel iGPUs</strong>, you have two types of tone-mapping methods: OpenCL and VPP. The latter one does not support fine tuning options.</p>
<p><strong>OpenCL:</strong> Follow the instructions from <a href="https://github.com/intel/compute-runtime/releases">intel-compute-runtime</a>.
If you are using the official Docker image or the one from linuxserver this step can be skipped.</p>
<p><strong>VPP:</strong> Make sure <code>jellyfin-ffmpeg</code> 4.4.1-2 or higher is installed.
Previous versions did not ship <code>intel-media-driver</code> thus it was required to be installed manually.</p>
<ul>
<li>When running on docker, the <strong>privileged</strong> flag is required for the OpenCL device to be recognized.
You can do this by adding <code>--privileged</code> to your docker command or <code>privileged: true</code> to your docker compose file.</li>
</ul>
</li>
</ul>
<div class="WARNING"><h5>Warning</h5><p>Tone-mapping on Intel VA-API and QSV <strong>requires an iGPU that supports 10-bit decoding</strong>, such as i3-7100 or J4105.</p>
</div>
<div class="IMPORTANT"><h5>Important</h5><p>Do <strong>not use</strong> the <code>intel-opencl-icd</code> package from your distro&#39;s repository since they were not built with <code>RELEASE_WITH_REGKEYS</code> enabled, which is required for P010 pixel interop flags.</p>
</div>
</li>
<li><p><strong>Debugging:</strong> Check the OpenCL device status. You will see corresponding vendor name if it goes well.</p>
<ul>
<li><p>Use <code>clinfo</code>: Install <code>clinfo</code> before using it. <code>sudo apt install -y clinfo</code> on Debian/Ubuntu or <code>sudo pacman -Sy clinfo</code> on Arch. Then <code>sudo clinfo</code>.</p>
</li>
<li><p>Use <code>jellyfin-ffmpeg</code>: <code>/usr/lib/jellyfin-ffmpeg/ffmpeg -v debug -init_hw_device opencl</code></p>
</li>
</ul>
</li>
</ol>
<h2 id="verifying-transcodes">Verifying Transcodes</h2>
<p>To verify that you are using the proper libraries, run this command against your transcoding log.
This can be found at <code>Admin Dashboard &gt; Logs</code>, and <code>/var/log/jellyfin</code> if installed via the apt repository.</p>
<pre><code class="lang-sh">grep -A2 &#39;Stream mapping:&#39; /var/log/jellyfin/ffmpeg-transcode-&lt;random-id&gt;&gt;.log
</code></pre><p>This returned the following results.</p>
<pre><code class="lang-data">...
Stream mapping:
Stream #0:0 -&gt; #0:0 (hevc (native) -&gt; h264 (h264_qsv))
Stream #0:1 -&gt; #0:1 (aac (native) -&gt; mp3 (libmp3lame))
...
</code></pre><p><code>Stream #0:0</code> used software (VAAPI Decode can also say native) to decode HEVC and used HWA to encode.</p>
<pre><code class="lang-data">...
Stream mapping:
Stream #0:0 -&gt; #0:0 (h264 (hevc_qsv) -&gt; h264 (h264_qsv))
Stream #0:1 -&gt; #0:1 (flac (native) -&gt; mp3 (libmp3lame))
...
</code></pre><p><code>Stream #0:0</code> used HWA for both. <code>hevc_qsv</code> to decode and <code>h264_qsv</code> to encode.</p>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/jellyfin/jellyfin-docs/blob/master/general/administration/hardware-acceleration.md/#L1" class="contribution-link">Improve this Doc</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In This Article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../../styles/docfx.js"></script>
    <script type="text/javascript" src="../../styles/main.js"></script>
  </body>
</html>
